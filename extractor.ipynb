{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/7TmfS7m/GJH5Cdq1F3zM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrianSward/colab-work/blob/main/extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook goes and fetches a website, extracts the text content, formats it into a more digestable format, and returns this information to the user. \n",
        "\n",
        "This will bypass things like:\n",
        "- ads \n",
        "- paywalls *(assuming the text is delivered / an immediate log-in is not required)*\n",
        "\n",
        "It also removes **ALL NON TEXT**, for good or bad. So there will be no pictures, videos, etc."
      ],
      "metadata": {
        "id": "MYU2uptWq3Dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function was taken from my Jupyter Notebook [here](https://github.com/BrianSward/colab-work/blob/main/fake_news_machine.ipynb). I wanted to see what was being returned from the scraping portion of my machine learning notebook and check for any strange artifacts or anomalies that could alter the accuracy of my model.\n"
      ],
      "metadata": {
        "id": "5U-aIDYu3GIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trafilatura"
      ],
      "metadata": {
        "id": "KmmVsQh2K_cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for the web scraping\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import numpy as np\n",
        "import requests\n",
        "import trafilatura\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "MnAQf8rYLdgG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beautifulsoup_extract_text_fallback(response_content):\n",
        "    \"\"\"\n",
        "    Extract text from HTML using BeautifulSoup.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(response_content, 'html.parser')\n",
        "    text = soup.find_all(text=True)\n",
        "    blacklist = ['[document]', 'noscript', 'header', 'html', 'meta', 'head', 'input', 'script', 'style']\n",
        "    cleaned_text = ' '.join(item for item in text if item.parent.name not in blacklist).replace('\\t', '')\n",
        "    return cleaned_text.strip()\n",
        "\n",
        "def extract_text_from_single_web_page(url):\n",
        "    \"\"\"\n",
        "    Extract text from a web page using Trafilatura or BeautifulSoup.\n",
        "    \"\"\"\n",
        "    downloaded_url = trafilatura.fetch_url(url)\n",
        "    try:\n",
        "        extracted_data = trafilatura.extract(downloaded_url, output_format='json', with_metadata=True, include_comments=False,\n",
        "                                date_extraction_params={'extensive_search': True, 'original_date': True})\n",
        "    except AttributeError:\n",
        "        extracted_data = trafilatura.extract(downloaded_url, json_output=True, with_metadata=True,\n",
        "                                date_extraction_params={'extensive_search': True, 'original_date': True})\n",
        "    if extracted_data:\n",
        "        json_output = json.loads(extracted_data)\n",
        "        return json_output['text']\n",
        "    else:\n",
        "        try:\n",
        "            resp = requests.get(url)\n",
        "            # We will only extract the text from successful requests:\n",
        "            if resp.status_code == 200:\n",
        "                return beautifulsoup_extract_text_fallback(resp.content)\n",
        "            else:\n",
        "                # This line will handle for any failures in both the Trafilature and BeautifulSoup4 functions:\n",
        "                return np.nan\n",
        "        # Handling for any URLs that don't have the correct protocol\n",
        "        except requests.exceptions.MissingSchema:\n",
        "            return np.nan\n",
        "\n",
        "# Get input URL from user\n",
        "user_url = input(\"Provide me a URL: \")\n",
        "print()\n",
        "\n",
        "try:\n",
        "    # Extract text from the web page\n",
        "    page_text = extract_text_from_single_web_page(url=user_url)\n",
        "\n",
        "    # Split the text into paragraphs and wrap each paragraph to a maximum of 80 characters per line\n",
        "    paragraphs = str(page_text).split(\"\\n\")\n",
        "    for paragraph in paragraphs:\n",
        "        wrapped_paragraph = textwrap.wrap(paragraph, width=80)\n",
        "        # Print the wrapped paragraph lines\n",
        "        for line in wrapped_paragraph:\n",
        "            print(line)\n",
        "        # Print a blank line to separate paragraphs\n",
        "        print()\n",
        "except ValueError:\n",
        "    print(\"Invalid URL entered.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl165x-UGQs3",
        "outputId": "84145810-b419-409d-9778-0a1018e70ad3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide me a URL: https://www.mlive.com/life/2023/04/willie-nelson-to-celebrate-his-90th-birthday-on-the-road-in-michigan-in-2023.html\n",
            "\n",
            "CLARKSTON, MI - Willie Nelson is going on the road again. This time, to\n",
            "celebrate his 90th birthday. The living legend will bring his Outlaw Music\n",
            "Festival tour to Pine Knob Music Theatre on Friday, September 22.\n",
            "\n",
            "Also in concert will be Bobby Weir & Wolf Bros. featuring The Wolfpack, The\n",
            "String Cheese Incident and Particle Kid. Tickets go on sale Friday, April 28 at\n",
            "10 a.m.\n",
            "\n",
            "Nelson said he wanted to celebrate his milestone 90th birthday, which is on\n",
            "April 29, on the road with his friends, family and fans.\n",
            "\n",
            "“I am so thrilled to announce these additional dates for our 2023 Outlaw Music\n",
            "Festival Tour,” said Nelson. “I can’t wait to keep the celebration of my 90th\n",
            "birthday going into the fall with this great lineup of artists, my friends and\n",
            "family, and of course, the amazing fans.”\n",
            "\n",
            "RELATED: Every concert coming to Pine Knob for its 2023 summer concert season\n",
            "\n",
            "At 90, Nelson continues his legendary career accolades winning two Grammy Awards\n",
            "in 2023. A five-part documentary film on his life and career premiered at\n",
            "Sundance this year and Nelson also released a new album, “I Don’t Know A Thing\n",
            "About Love.” He has also been nominated for the Rock and Roll Hall of Fame.\n",
            "\n",
            "MORE FROM MLIVE:\n",
            "\n",
            "Detroit’s first indoor/outdoor dog park and beer garden set to open\n",
            "\n",
            "Michigan airport lands in top 10 for best airport food in the entire country\n",
            "\n",
            "‘Forget Chicago!’ Reader’s Digest suggests this ‘underrated’ Michigan city\n",
            "instead\n",
            "\n",
            "Michigan has an actual ‘Star Wars’ Mos Eisley Cantina which opens every May 4th\n",
            "\n",
            "One of the top skinny-dipping spots in the world is apparently in Michigan\n",
            "\n"
          ]
        }
      ]
    }
  ]
}